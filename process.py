"""
Example of a confidential workload processing data from 2 data owners and sending the results to 1 data user.
The confidential workload handles 3 events: one to perform a collaborative analysis example, one to perform a confidential AI (training the AI ​​model), and one to trigger the data owners' data quality checks.
"""

import logging
import time
import json
import duckdb

from dv_utils import default_settings, ContractManager,audit_log,LogLevel

logger = logging.getLogger(__name__)

# let the log go to stdout, as it will be captured by the cage operator
logging.basicConfig(
    level=default_settings.log_level,
    format="%(asctime)s - %(levelname)s - %(message)s",
)


# define an event processing function
def event_processor(evt: dict):
    """
    Process an incoming event
    Exception raised by this function are handled by the default event listener and reported in the logs.
    """
    logger.info(f"Processing event {evt}")
    
    # dispatch events according to their type
    evt_type =evt.get("type", "")

    if evt_type == "CHECK_DATA_QUALITY":
        # use the CHECK_DATA_QUALITY event processor dedicated function
        logger.info(f"Use the check data quality event processor")
        check_data_quality_contracts_event_processor(evt)
    elif evt_type == "CHECK_COMMON__DEMO_CUSTOMERS":
        # use the CHECK_COMMON__DEMO_CUSTOMERS event processor dedicated function
        logger.info(f"Use the check common customers demo event processor")
        check_common_customers_demo_event_processor(evt)
    else:
        # use the GENERIC event processor function, that basicaly does nothing
        logger.info(f"Unhandled message type, use the generic event processor")
        generic_event_processor(evt)


def generic_event_processor(evt: dict):
    pass

def check_data_quality_contracts_event_processor(evt: dict):
    #audit logs are generated by the dv_utils sdk
    try:
        contractManager=ContractManager()
        contractManager.check_contracts_for_collaboration_space(default_settings.collaboration_space_id)
    except Exception as e:
        logger.error(e)

def check_common_customers_demo_event_processor(evt: dict):
    logger.info(f"---------------------------------------------------------")
    logger.info(f"|                    START PROCESSING                   |")
    logger.info(f"|                                                       |")
    start_time = time.time()
    logger.info(f"|    Start time:  {start_time} secs               |")
    logger.info(f"|                                                       |")
    audit_log(f"Start processing event: {evt.get('type', '')}.",LogLevel.INFO)
    try:
        collaboration_space_id=default_settings.collaboration_space_id
        logger.info(f"| 1. Get data contracts                                 |")
        logger.info(f"|                                                       |")
        contractManager=ContractManager()
        data_contracts=contractManager.get_contracts_for_collaboration_space(collaboration_space_id)
        if data_contracts != None and len(data_contracts)>0:
            #Create in memory duckdb (encrypted memory on confidential computing)
            con = duckdb.connect(database=":memory:")
            
            #Add connector settings to duckdb con for all data contracts (2 data contracts in this example)
            con = data_contracts[0].connector.add_duck_db_connection(con)
            con = data_contracts[1].connector.add_duck_db_connection(con)

            logger.info(f"| 2. Evaluate common customers                          |")
            #Create duckdb in memory db for optimisation
            query=f"SELECT * FROM {data_contracts[0].connector.get_duckdb_source()}"
            res=con.sql("CREATE OR REPLACE TABLE customers_list_1 AS "+query) 
            query=f"SELECT * FROM {data_contracts[1].connector.get_duckdb_source()}"
            res=con.sql("CREATE OR REPLACE TABLE customers_list_2 AS "+query) 
            #Common customers by name
            #Create duckdb query
            query="SELECT COUNT(*) as total FROM customers_list_1,customers_list_2 WHERE (customers_list_1.customer_name=customers_list_2.customer_name)"
            df = con.sql(query).df()
            common_customers_by_name=df["total"].to_string(index=False)
            logger.info(f"|    Common customers by name: {common_customers_by_name}                     |")
            
            #Common customers by email
            #Create duckdb query
            query="SELECT COUNT(*) as total FROM customers_list_1,customers_list_2 WHERE (customers_list_1.customer_email=customers_list_2.customer_email)"
            df = con.sql(query).df()
            common_customers_by_email=df["total"].to_string(index=False)
            logger.info(f"|    Common customers by email: {common_customers_by_email}                    |")

            #Common customers by company
            #Create duckdb query
            query="SELECT COUNT(*) as total FROM customers_list_1,customers_list_2 WHERE (customers_list_1.customer_company=customers_list_2.customer_company)"
            df = con.sql(query).df()
            common_customers_by_company=df["total"].to_string(index=False)
            logger.info(f"|    Common customers by company: {common_customers_by_company}                  |")
            logger.info(f"|                                                       |")
            
            #Remove in memory database 
            res=con.sql("DROP TABLE customers_list_1") 
            res=con.sql("DROP TABLE customers_list_2") 

            #Write outputs for data user
            #For now the output is written in an encrypted drive only accessible for data user
            #TODO Connector for data users (write) have to be created
            logger.info(f"| 3. Send output                                        |")
            output_json={}
            output_json["common_customers"]={"by_name":common_customers_by_name,"by_email":common_customers_by_email,"by_company":common_customers_by_company}
            with open(default_settings.data_user_output_location+'/report.json', 'w', newline='') as file:
                    file.write(json.dumps(output_json, indent=4))
            logger.info(f"|                                                       |")
            execution_time=(time.time() - start_time)
            logger.info(f"|    Execution time:  {execution_time} secs           |")
            logger.info(f"|                                                       |")
            logger.info(f"--------------------------------------------------------")

        else:
            logger.error(f"No data contract available for collaboration_space_id: {collaboration_space_id}")
    except Exception as e:
        logger.error(e)